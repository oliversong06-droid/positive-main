# -*- coding: utf-8 -*-
"""ACDT model v1: Text to Emotion

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FuSsq0qI1DlcXu9UwYit9l70zoW0aZla
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import re

# --- 1. 데이터 로드 ---
# 'emotion_sentimen_dataset.csv' 파일 경로를 정확히 지정하세요.
file_path = './emotion_sentimen_dataset.csv'

try:
    df = pd.read_csv(file_path, encoding='latin1')
except FileNotFoundError:
    print(f"오류: {file_path} 경로를 찾을 수 없습니다.")
    raise
except Exception as e:
    print(f"파일 로딩 오류: {e}")
    raise

print(f"원본 데이터 크기: {df.shape}\n")

# --- 2. 데이터 정제 (영어 전용) ---
try:
    df_renamed = df.rename(columns={'Emotion': 'label', 'text': 'text'})
    df_clean = df_renamed[['text', 'label']]
except KeyError as e:
    print(f"오류: 'text' 또는 'Emotion' 컬럼을 찾을 수 없습니다. {e}")
    raise

# (핵심) "영어 전용" 가정을 코드로 구현합니다.
# 알파벳(a-z, A-Z)과 공백(space)을 제외한 모든 문자를 제거합니다.
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text) # 오직 영어와 공백만 남김
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df_clean['text'] = df_clean['text'].apply(clean_text)

df_clean.dropna(subset=['text', 'label'], inplace=True)
df_final = df_clean[df_clean['text'] != ""]


# --- 3. 라벨 매핑 (*** 'neutral' 항목을 여기서 삭제 ***) ---
# 'neutral'을 맵에서 제외하여, 67만 개의 데이터를 학습에서 제외시킵니다.

label_map = {
    # 1. joy
    'happiness': 'joy',
    'fun': 'joy',
    'enthusiasm': 'joy',
    'relief': 'joy',
    'love': 'joy',

    # 2. sadness
    'sadness': 'sadness',
    'empty': 'sadness',
    'boredom': 'sadness',

    # 3. anger
    'anger': 'anger',

    # 4. fear
    'worry': 'fear',

    # 5. disgust
    'hate': 'disgust',

    # 6. surprise
    'surprise': 'surprise'

    # 7. 'neutral': 'neutral' <-- 이 항목을 의도적으로 삭제
}

# 6가지 감정으로 매핑합니다.
df_final['label'] = df_final['label'].map(label_map)

# *** 'neutral' 67만개 데이터가 여기서 모두 제거(drop)됩니다. ***
df_final = df_final.dropna(subset=['label'])

print("--- 6가지 감정 ('neutral' 제외)으로 정제된 데이터 ---")
print(df_final['label'].value_counts())
print("\n" + "="*50 + "\n")


# --- 4. 훈련 / 테스트 데이터 분리 ---
X = df_final['text']
y = df_final['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,       # 20%를 테스트 데이터로 사용
    random_state=42,     # 재현 가능성을 위한 시드
    stratify=y          # 6개 감정 간의 불균형을 맞춥니다
)

print(f"훈련 데이터 (6개 감정): {X_train.shape[0]}개")
print(f"테스트 데이터 (6개 감정): {X_test.shape[0]}개\n")


# --- 5. TF-IDF 벡터화 (영어 불용어 처리) ---
vectorizer = TfidfVectorizer(
    max_features=5000,
    stop_words='english' # 'a', 'the', 'is' 등 영어 불용어 제거
)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

print(f"TF-IDF 벡터 shape (훈련): {X_train_tfidf.shape}")
print(f"TF-IDF 벡터 shape (테스트): {X_test_tfidf.shape}\n")


# --- 6. 모델 학습 ---
model = LogisticRegression(
    max_iter=1000,
    random_state=42,
    # 6개 감정 간의 불균형('joy' 8만 vs 'fear' 4천)을
    # 해소하기 위해 'balanced' 옵션을 사용합니다.
    class_weight='balanced'
)

print("모델 학습을 시작합니다 (6개 감정, 가중치 적용)...")
model.fit(X_train_tfidf, y_train)
print("모델 학습 완료.\n")


# --- 7. 모델 평가 (6개 감정) ---
y_pred = model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print(f"--- Model v1 성능 (6개 감정) ---")
print(f"정확도 (Accuracy): {accuracy * 100:.2f}%\n")

print("--- Classification Report (6개 감정) ---")
print(classification_report(y_test, y_pred, labels=sorted(y.unique())))
print("\n" + "="*50 + "\n")


# --- 8. 오류 분석 (Error Board v1) ---
error_df = pd.DataFrame()
error_df['text'] = X_test[y_test != y_pred]
error_df['actual_label'] = y_test[y_test != y_pred]
error_df['predicted_label'] = y_pred[y_test != y_pred]

print(f"--- Error Board v1 (모델이 틀린 샘플 10개) ---")
print(error_df.head(10))

# --- 9. 실시간 예측 테스트 (영어 전용) ---
# Colab 노트북의 맨 마지막에 이 셀을 추가로 실행해서 테스트하세요.

def predict_emotion(new_diary_entry):
    # 2단계와 동일한 정제(영어만 남기기) 실행
    cleaned_text = clean_text(new_diary_entry)

    # 5단계와 동일한 벡터화 실행
    text_vector = vectorizer.transform([cleaned_text])

    # 6단계의 'model'로 예측 실행
    prediction = model.predict(text_vector)

    print(f"\n--- 실시간 감정 추출 테스트 ---")
    print(f"입력 (영어): {new_diary_entry}")
    print(f"예측된 감정: {prediction[0]}")

# 테스트
print("\n" + "="*50 + "\n")
predict_emotion("I watched a great movie today.")
predict_emotion("This is terrible, I hate it so much.")
predict_emotion("I feel so worried about the test tomorrow.")

# 1. 테스트하고 싶은 새로운 일기 문장
new_diary_entry = input("Can you explain today's happening?")
# (다른 문장으로 바꿔보세요: "This is terrible, I hate it.")

# 2. 훈련 때와 동일하게 텍스트 정제
cleaned_text = clean_text(new_diary_entry)

# 3. 훈련된 'vectorizer'로 텍스트를 숫자로 변환
# (주의: .transform()은 리스트를 입력받으므로 [ ]로 감싸야 함)
text_vector = vectorizer.transform([cleaned_text])

# 4. 훈련된 'model'로 감정 예측 (추출)
prediction = model.predict(text_vector)
probability = model.predict_proba(text_vector)

# 5. 결과 출력
print(f"--- 실시간 감정 추출 테스트 ---")
print(f"입력 텍스트: {new_diary_entry}")
print(f"예측된 감정: {prediction[0]}") # 0번째 인덱스에 결과가 들어있습니다.

# (참고) 7개 감정 각각의 확률 확인하기
print("\n--- 7개 감정 확률 ---")
print(list(zip(model.classes_, probability[0])))